# [Booking.com Scraper](https://github.com/MrAnon89/Booking.com-Scraper)
Start: 13/12/2024  |  Finish: 20/12/2024

The Booking.com Scraper automates the process of extracting hotel listings, prices, ratings, and availability from Booking.com. It helps users gather valuable travel data efficiently without manual searching. The scraper is designed to handle dynamic content using Selenium and organize the extracted data using Pandas.

## 🏨The story behind the project:
While searching for hotels, I realized how time-consuming it was to manually compare prices, availability, and ratings. Each search required multiple filters and scrolling, making the process inefficient. As a software engineer, I wanted to simplify this by automating the task.

With this in mind, I created a Booking.com scraper that collects and structures the data in a readable format. The process involved multiple phases: planning the scraper logic, setting up Selenium to navigate the website dynamically, structuring the extracted data using Pandas, and creating a simple GUI with Tkinter for ease of use. Debugging was a key part of the journey, ensuring the scraper ran smoothly across different queries.

## 📑The framework and libraries I worked with:
1. **Selenium**
   - Automates web interactions to extract data dynamically.
   - Handles JavaScript-loaded content.
   - Navigates Booking.com’s search results and extracts hotel details.
   
2. **Pandas**
   - Structures the extracted data into a DataFrame.
   - Provides easy exporting to CSV or Excel for further analysis.
   - Helps in filtering and cleaning the scraped data.

3. **Tkinter**
   - Builds a simple graphical interface for user input.
   - Allows users to input search criteria (location, check-in dates, etc.).
   - Displays scraping progress in real-time.

4. **Time**
   - Introduces delays to mimic human interaction and prevent detection.
   - Ensures smooth automation without overwhelming the website.

## 🤷‍♂️What I learned:
- Web scraping requires handling dynamic content and JavaScript-based websites.
- Structuring scraped data effectively is as important as collecting it.
- GUI integration makes automation tools more user-friendly.
- Debugging and optimizing automation scripts is crucial for reliability.

